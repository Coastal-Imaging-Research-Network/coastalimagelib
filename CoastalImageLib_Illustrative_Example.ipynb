{"cells":[{"cell_type":"markdown","metadata":{},"source":["### Illustrative Example Script\n","\n","The Illustrative Example data is from six fixed cameras on top a 43-m tower (known as the Argus Tower) at the Army Corps of Engineers Field Research Facility in Duck, NC. \n","\n","Single frames are provided to demonstrate calling mergeRectify() directly. These 6 oblique frames were taken from the .avi files provided, and are included in color.\n","\n","Finally, a set of 5 frames for each camera is included to demonstrate calling mergeRectify() in a loop to rectify images at subsequent timestamps.\n","\n","Extrinsic and intrinsic values for each camera are provided in both direct linear transform coefficient format as well as in CIRN convention."]},{"cell_type":"markdown","id":"1e86ebbd","metadata":{},"source":["Download example images from https://github.com/mailemccann/CIRN-Quantitative-Coastal-Imaging-Toolbox/tree/master/X_FixedMultCamDemoData/collectionData\n","\n","There should be 6 subfolders, each corresponding to a different camera. Ensure that these folders are unzipped and the file path location strings are changed in the below sections loading the images to correspond with where the downloaded images are on your drive. An easy way to find the pull path is to open file explorer, find the file or folder, and click \"copy path\""]},{"cell_type":"markdown","metadata":{},"source":["Let's start with our imports. \n","\n","Ensure that each package is installed prior to running your script, in addition to the package dependencies described in section 2 of the CoastalImageLib User Manual. \n","Suggested install is via 'pip install ___'"]},{"cell_type":"code","execution_count":24,"metadata":{"trusted":true},"outputs":[],"source":["# CoastalImageLib imports\n","import corefunctions as cf\n","import supportfunctions as sf\n","\n","# External imports\n","import numpy as np\n","import cv2 as cv\n","import matplotlib.pyplot as plt\n","import imageio\n","import os"]},{"cell_type":"markdown","metadata":{},"source":["Now, we can initialize the strings that contain our file information."]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true},"outputs":[],"source":["# Image, camera data, and video locations\n","# Change this string to match the location on your computer containing the subfolders of camera data\n","folder = 'C:\\\\Users\\\\mccan\\\\Desktop\\\\MiscWAM\\\\ExampleData'\n","\n","# These are the 'tags' for each camera. They are used\n","# to distinguish between camera files, as well as\n","# intrinsic and extrinsic values contained in the .yaml file, \n","# loaded in the next code block.\n","cams = ['c1','c2','c3','c4','c5','c6']"]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[],"source":["# This is our list of strings containing the file name and\n","# locations for each FRAME (.jpg file) file we want to rectify\n","\n","file_base = '1444314601.Thu.Oct.08_14_30_01.GMT.2015.argus02b.' \n","\n","# Frames\n","image_list = [os.path.join(folder,i,(file_base + i + '.timex.jpg')) for i in cams]"]},{"cell_type":"markdown","metadata":{},"source":["Next, let's load our intrinsic and extrinsic values, as well as relevant camera metadata, into our \"camera\" objects. We do this by initializing an array of CameraData objects with our calibration information. "]},{"cell_type":"code","execution_count":17,"metadata":{"trusted":true},"outputs":[],"source":["# Location of our calibration data, stored in a .yaml file inside this repository\n","calibration_loc = ('cameraData.yml')\n","\n","# Call a support function to format .yaml files into CIRN convention\n","m, ex = sf.loadYamlDLT(calibration_loc,cams) "]},{"cell_type":"markdown","metadata":{},"source":["Tags:\n","coords = 'local', because our calibration data is already in local (FRF) coordinates\n","origin = 'None', because we don't need to specify a local origin since we are already in local coordinates\n","mType = 'DLT', because our cameras were calibrated using the Direct Linear Transform method. Most cameras will not be calibrated this way. For more information on each format of intrinsic values, see the CoastalImageLib user manual."]},{"cell_type":"code","execution_count":18,"metadata":{"trusted":true},"outputs":[],"source":["cameras = np.empty(len(cams),dtype=object)\n","for i in range(len(cams)):\n","    cameras[i] = cf.CameraData(m[i], ex[i], coords = 'local', origin= 'None', mType = 'DLT', nc=3)"]},{"cell_type":"markdown","metadata":{},"source":["The next step is to initialize the rectification grid. This is the target grid on which the nadir image will appear. The grid is created using the XYZGrid object."]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":true},"outputs":[],"source":["# Grid boundaries\n","xMin = 0\n","xMax = 500\n","yMin = -500\n","yMax = 1200\n","dy = 1\n","dx = 1\n","z = 0\n","\n","grid = cf.XYZGrid([xMin,xMax], [yMin,yMax], dx, dy, z)"]},{"cell_type":"markdown","metadata":{},"source":["## Rectifying Oblique Frames"]},{"cell_type":"markdown","metadata":{},"source":["Let's first try rectifying single frames from each camera and merging the images in color. In python, the main difference between grayscale and color images is the number of channels, or the depth of the image matrix. CoastalImageLib can accomodate both grayscale (1 channel) and color/ RGB (3 channels).  "]},{"cell_type":"code","execution_count":22,"metadata":{"trusted":true},"outputs":[],"source":["rect_frame_gray = cf.mergeRectify(image_list, cameras, grid)"]},{"cell_type":"code","execution_count":23,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["-1"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["# Display our rectified frame\n","# Click 'x' on the pop- up window to leave display\n","cv.imshow('Rectified Frame',rect_frame_gray.astype(np.uint8))\n","cv.waitKey(0)"]},{"cell_type":"markdown","metadata":{},"source":["## Rectifying Multiple Oblique Frames"]},{"cell_type":"markdown","metadata":{},"source":["What if we want to rectify a sequence of oblique frames, for example, videos that have been converted to single frames, then save to one merged video file?\n","\n","In this case, we need to set up a loop to go through each *timestamp* of the frames, and merge all the cameras at that *timestamp*, then save each merged frame into a videwriter object.\n","\n","Ultimately, you will have to write your own for loop to accomodate your specific application."]},{"cell_type":"code","execution_count":26,"metadata":{"trusted":true},"outputs":[{"ename":"FileNotFoundError","evalue":"No such file: 'C:\\Users\\mccan\\Desktop\\MiscWAM\\ExampleDatac1\\281_Oct.08\\1444314601.Thu.Oct.08_14_30_01.GMT.2015.argus02b.c1.raw'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m<ipython-input-26-8ab5ccf44f84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfile_changes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mpaths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutFile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformatArgusFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mcurr_rect_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmergeRectify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcameras\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# Display the current frame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\mccan\\Documents\\GitHub\\CoastalImageLib\\corefunctions.py\u001b[0m in \u001b[0;36mmergeRectify\u001b[1;34m(input_frames, cameras, grid)\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mI\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[1;31m# Load image from current camera\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m             \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimageio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mI\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_frames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnc\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mnc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imageio\\core\\functions.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(uri, format, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;31m# Get reader and read first\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m     \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"i\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imageio\\core\\functions.py\u001b[0m in \u001b[0;36mget_reader\u001b[1;34m(uri, format, mode, **kwargs)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# Create request object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m     \u001b[0mrequest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;31m# Get format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imageio\\core\\request.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, uri, mode, **kwargs)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;31m# Parse what was given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_uri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;31m# Set extension\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imageio\\core\\request.py\u001b[0m in \u001b[0;36m_parse_uri\u001b[1;34m(self, uri)\u001b[0m\n\u001b[0;32m    258\u001b[0m                 \u001b[1;31m# Reading: check that the file exists (but is allowed a dir)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No such file: '%s'\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m                 \u001b[1;31m# Writing: check that the directory to write to does exist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mFileNotFoundError\u001b[0m: No such file: 'C:\\Users\\mccan\\Desktop\\MiscWAM\\ExampleDatac1\\281_Oct.08\\1444314601.Thu.Oct.08_14_30_01.GMT.2015.argus02b.c1.raw'"]}],"source":["# Here, we will only work with 5 frames per camera\n","\n","start_time = 1444314601 # Timestamp of the first frame, in UTC time\n","end_time = 1444323601 # Timestamp of the last frame, in UTC time\n","\n","# The timestamp of each frame is contained in the file name\n","# For this example data, the images are time averaged and sampled every 30 minutes\n","# Therefore, we are looking for the time stamps in epoch time at every 1800 seconds\n","file_changes = np.arange(start_time, end_time, 1800)\n","\n","for f in file_changes:\n","    paths, outFile = sf.formatArgusFile(cams,folder,f)\n","    rect_frame = cf.mergeRectify(paths, cameras, grid)\n","    \n","    # Display the current frame\n","    # Click 'x' on the pop- up window to move on to next frame\n","    disp_str = 'Merged and Rectified Frame ' + str(f)\n","    cv.imshow(disp_str, rect_frame)\n","    cv.waitKey(0)\n","\n","    # Save rectified video to drive\n","    if f == start_time:\n","        # Initialize openCV videowriter object\n","        out = cv.VideoWriter(outFile,cv.VideoWriter_fourcc('M','J','P','G'), 2, (np.shape(rect_frame)[1],np.shape(rect_frame)[0]),0)\n","        all_frames = rect_frame\n","        \n","    # Write frame to .avi\n","    out.write(rect_frame.astype(np.uint8))\n","\n","    # Saving array with all frames to use in last step of tutorial (image statistics)\n","    all_frames = np.dstack((all_frames,rect_frame))\n","\n","# Release videowriter object\n","out.release()\n","    "]},{"cell_type":"markdown","metadata":{},"source":["## Rectifying Oblique Videos\n","## In order to utilize this section, please reach out to the author (Maile McCann, mailemcc@usc.edu) for example video files\n","## Otherwise, load your own .avi files via the video_list path"]},{"cell_type":"markdown","metadata":{},"source":["Finally, let's rectify our videos!\n","\n","numFrames is the number of frames we would like to rectify. Here, our video is sampled at 2 Hz, and we would like 10 seconds of data. Therefore, numFrames = 2*10"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["numFrames = 20 # 2 fps for 10 seconds\n","\n","video_list = [os.path.join(folder,i,(file_base + i + '.avi')) for i in cams]\n","# Call rectVideos !\n","rect = cf.rectVideos(video_list, cameras, grid, numFrames)"]},{"cell_type":"markdown","metadata":{},"source":["Now, you have an object containing your rectified frames. However, your video is saved to your drive in your working directory as the input file name + 'video_capture.rect.avi'."]},{"cell_type":"markdown","metadata":{},"source":["## Creating a Pixel Timestack"]},{"cell_type":"markdown","metadata":{},"source":["Let's create subsampled pixel timestacks. These timestacks are for use in algorithms such as bathymetric inversion, surface current estimation, or run-up calculations. Pixel timestacks show variations in pixel intensity over time."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Here, we will create one pixel stack at a single timestamp and display the location on oblique images\n","\n","# Ultimately, you will need to write your own for loop to accomodate your specific application\n","\n","# Click 'x' to exit image displays\n","\n","# Alongshore Transect\n","x = 300\n","yMin = 900\n","yMax = 1200\n","dy = 5\n","alongshore_trans = cf.XYZGrid([x], [yMin,yMax], dx, dy, z)\n","\n","start_time = 1444314601 # Timestamp of the first frame, in UTC time\n","paths, outFile = sf.formatArgusFile(cams,folder,start_time)\n","rect = cf.pixelStack(paths, alongshore_trans, cameras, disp_flag=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Cross- shore Transect\n","xMin = 100\n","xMax = 0\n","y = 1200\n","dx = 5\n","alongshore_trans = cf.XYZGrid([xMin, xMax], [y], dx, dy, z)\n","rect = cf.pixelStack(paths, alongshore_trans, cameras, disp_flag=1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Pixel Grid\n","xMin = 400\n","xMax = 150\n","yMin = 500\n","yMax = 1200\n","dx = 5\n","dy = 5\n","alongshore_trans = cf.XYZGrid([xMin, xMax], [y], dx, dy, z)\n","rect = cf.pixelStack(paths, alongshore_trans, cameras, disp_flag=1)"]},{"cell_type":"markdown","metadata":{},"source":["## Calculating Image Statistics"]},{"cell_type":"markdown","metadata":{},"source":["Lastly, let's calculate sample statistical image products. These products include Darkest, Brightest, Timex, and Variance from an array of images. For detailed information, see the accompanying SoftwareX publication, or the CoastalImageLib User Manual."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Let's find the image statistics from the rectified array, \"all_frames\" we created in \"Rectifying Multiple Oblique Frames\"\n","# Save flag indicates that the resulting image products will be saved \n","# in the current working directory\n","\n","# Click 'x' to exit image display\n","cf.imageStats(all_frames, save_flag = 1)"]}],"metadata":{"interpreter":{"hash":"dd07ca0728434bbb8f6c676335187387b0908d0533b5b641a12ddd36fe4fb1d5"},"kernelspec":{"display_name":"Python 3.8.8 64-bit ('base': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}
