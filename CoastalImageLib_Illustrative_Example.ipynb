{"cells":[{"cell_type":"markdown","metadata":{},"source":["### Illustrative Example Script\n","\n","The Illustrative Example data is from six fixed cameras on top a 43-m tower (known as the Argus Tower) at the Army Corps of Engineers Field Research Facility in Duck, NC. \n","\n","Each full oblique video is 1 minute long and captured at 2 frames per second. Each video was recorded simultaneously. Six separate grayscale .avi files, corresponding to each camera collection, are included. \n","\n","Single frames are provided to demonstrate calling mergeRectify() directly. These 6 oblique frames were taken from the .avi files provided, and are included in color and grayscale.\n","\n","Finally, a set of 5 frames for each camera is included to demonstrate calling mergeRectify() in a loop to rectify images at subsequent timestamps.\n","\n","Extrinsic and intrinsic values for each camera are provided in both direct linear transform coefficient format as well as in CIRN convention."]},{"cell_type":"markdown","metadata":{},"source":["Let's start with our imports. \n","\n","Ensure that each package is installed prior to running your script, in addition to the package dependencies described in section 2 of the CoastalImageLib User Manual. \n","Suggested install is via 'pip install ___'"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[],"source":["# CoastalImageLib imports\n","import corefunctions as cf\n","import supportfunctions as sf\n","\n","# External imports\n","import numpy as np\n","import cv2 as cv\n","import matplotlib.pyplot as plt\n","import imageio"]},{"cell_type":"markdown","metadata":{},"source":["Now, we can initialize the strings that contain our file information."]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[],"source":["# Image, camera data, and video locations\n","folder = 'C:/Users/mccan/Desktop/MiscWAM/304_Oct.31/'\n","\n","# These are the 'tags' for each camera. They are used\n","# to distinguish between camera files, as well as\n","# intrinsic and extrinsic values contained in the .yaml file, \n","# loaded in the next code block.\n","cams = ['c1','c2','c3','c4','c5','c6']"]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true},"outputs":[],"source":["# This is our list of strings containing the file name and\n","# locations for each FRAME (.jpg file) file we want to rectify\n","\n","# Grayscale frames\n","image_list_gray = [folder + i + '_frame.jpg' for i in cams]\n","\n","# RGB frames\n","image_list_rgb = [folder + i + '_frame_rgb.jpg' for i in cams]"]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[],"source":["# This is our list of strings containing the file name and\n","# locations for each VIDEO (.avi file) we want to rectify\n","video_list = [folder + '1604152800.Sat.Oct.31_14_00_00.GMT.2020.' + i + '.avi' for i in cams]"]},{"cell_type":"markdown","metadata":{},"source":["Next, let's load our intrinsic and extrinsic values, as well as relevant camera metadata, into our \"camera\" objects. We do this by initializing an array of CameraData objects with our calibration information. "]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":true},"outputs":[],"source":["# Location of our calibration data, stored in a .yaml file \n","calibration_loc = folder + 'cameraData.yml'\n","\n","# Call a support function to format .yaml files into CIRN convention\n","m, ex = sf.loadYamlDLT(calibration_loc,cams) "]},{"cell_type":"markdown","metadata":{},"source":["Tags:\n","coords = 'local', because our calibration data is already in local (FRF) coordinates\n","origin = 'None', because we don't need to specify a local origin since we are already in local coordinates\n","mType = 'DLT', because our cameras were calibrated using the Direct Linear Transform method. Most cameras will not be calibrated this way. For more information on each format of intrinsic values, see the CoastalImageLib user manual."]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":true},"outputs":[],"source":["cameras = np.empty(len(cams),dtype=object)\n","for i in range(len(cams)):\n","    cameras[i] = cf.CameraData(m[i], ex[i], coords = 'local', origin= 'None', mType = 'DLT',nc=3)"]},{"cell_type":"markdown","metadata":{},"source":["The next step is to initialize the rectification grid. This is the target grid on which the nadir image will appear. The grid is created using the XYZGrid object."]},{"cell_type":"code","execution_count":21,"metadata":{"trusted":true},"outputs":[],"source":["# Grid boundaries\n","xMin = 0\n","xMax = 500\n","yMin = -500\n","yMax = 1200\n","dy = 1\n","dx = 1\n","z = 0\n","\n","grid = cf.XYZGrid([xMin,xMax], [yMin,yMax], dx, dy, z)"]},{"cell_type":"markdown","metadata":{},"source":["## Rectifying Oblique Frames"]},{"cell_type":"markdown","metadata":{},"source":["Let's first try rectifying single frames from each camera and merging the images in both grayscale in color. In python, the main difference between grayscale and color images is the number of channels, or the depth of the image matrix. CoastalImageLib can accomodate both grayscale (1 channel) and color/ RGB (3 channels).  "]},{"cell_type":"markdown","metadata":{},"source":["First, in grayscale:"]},{"cell_type":"code","execution_count":22,"metadata":{"trusted":true},"outputs":[],"source":["rect_frame_gray = cf.mergeRectify(image_list_gray, cameras, grid)"]},{"cell_type":"code","execution_count":23,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["-1"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["# Display our rectified frame\n","# Click 'x' on the pop- up window to leave display\n","cv.imwrite('C:/Users/mccan/Desktop/drifterbackground.jpg',rect_frame_gray.astype(np.uint8))\n","cv.imshow('Rectified Frame, Gray',rect_frame_gray.astype(np.uint8))\n","cv.waitKey(0)"]},{"cell_type":"markdown","metadata":{},"source":["Next, in color:"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["rect_frame_rgb = cf.mergeRectify(image_list_rgb, cameras, grid)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Display our rectified frame\n","# Click 'x' on the pop- up window to leave display\n","cv.imshow('Rectified Frame, Color',rect_frame_rgb.astype(np.uint8))\n","cv.waitKey(0)"]},{"cell_type":"markdown","metadata":{},"source":["## Rectifying Multiple Oblique Frames"]},{"cell_type":"markdown","metadata":{},"source":["What if we want to rectify a sequence of oblique frames, for example, videos that have been converted to single frames.\n","\n","In this case, we need to set up a loop to go through each *timestamp* of the frames, and merge all the cameras at that *timestamp*.\n","\n","Ultimately, you will have to write your own for loop to accomodate your specific application."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Here, we will only work with 5 frames per camera, each sampled one second apart. \n","\n","start_time = 1604152800 # Timestamp of the first frame, in UTC time\n","end_time = start_time + 5 # Timestamp of the last frame, in UTC time\n","\n","# The timestamp of each frame is contained in the file name\n","file_changes = np.arange(start_time, end_time)\n","\n","for f in file_changes:\n","    curr_image_list = [folder + str(f) + '_' + i + '_frame_gray.jpg' for i in cams]\n","    curr_rect_frame = cf.mergeRectify(curr_image_list, cameras, grid)\n","    \n","    # Display the current frame\n","    # Click 'x' on the pop- up window to move on to next frame\n","    disp_str = 'Merged and Rectified Frame ' + str(f)\n","    cv.imshow(disp_str, curr_rect_frame)\n","    cv.waitKey(0)\n","    "]},{"cell_type":"markdown","metadata":{},"source":["## Rectifying Oblique Videos"]},{"cell_type":"markdown","metadata":{},"source":["Finally, let's rectify our videos!\n","\n","numFrames is the number of frames we would like to rectify. Here, our video is sampled at 2 Hz, and we would like 10 seconds of data. Therefore, numFrames = 2*10"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["numFrames = 20 # 2 fps for 10 seconds\n","\n","# Call rectVideos !\n","rect = cf.rectVideos(video_list, cameras, grid, numFrames)"]},{"cell_type":"markdown","metadata":{},"source":["Now, you have an object containing your rectified frames. However, your video is saved to your drive in your working directory as the input file name + 'video_capture.rect.avi'."]},{"cell_type":"markdown","metadata":{},"source":["## Creating a Pixel Timestack"]},{"cell_type":"markdown","metadata":{},"source":["Let's create subsampled pixel timestacks. These timestacks are for use in algorithms such as bathymetric inversion, surface current estimation, or run-up calculations. Pixel timestacks show variations in pixel intensity over time."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Here, we will create one pixel stack at a single timestamp and display the location on oblique images\n","\n","# Ultimately, you will need to write your own for loop to accomodate your specific application\n","\n","# Click 'x' to exit image displays\n","\n","# Alongshore Transect\n","x = 300\n","yMin = 900\n","yMax = 1200\n","dy = 5\n","alongshore_trans = cf.XYZGrid([x], [yMin,yMax], dx, dy, z)\n","rect = cf.pixelStack(im_list, alongshore_trans, cameras, disp_flag=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Cross- shore Transect\n","xMin = 100\n","xMax = 0\n","y = 1200\n","dx = 5\n","alongshore_trans = cf.XYZGrid([xMin, xMax], [y], dx, dy, z)\n","rect = cf.pixelStack(im_list, alongshore_trans, cameras, disp_flag=1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Pixel Grid\n","xMin = 400\n","xMax = 150\n","yMin = 500\n","yMax = 1200\n","dx = 5\n","dy = 5\n","alongshore_trans = cf.XYZGrid([xMin, xMax], [y], dx, dy, z)\n","rect = cf.pixelStack(im_list, alongshore_trans, cameras, disp_flag=1)"]},{"cell_type":"markdown","metadata":{},"source":["## Calculating Image Statistics"]},{"cell_type":"markdown","metadata":{},"source":["Lastly, let's calculate sample statistical image products. These products include Darkest, Brightest, Timex, and Variance from an array of images. For detailed information, see the accompanying SoftwareX publication, or the CoastalImageLib User Manual."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Let's find the image statistics from the rectified array from our videos\n","# Save flag indicates that the resulting image products will be saved \n","# in the current working directory\n","\n","# Click 'x' to exit image display\n","cf.imageStats(rect, save_flag = 1)"]}],"metadata":{"interpreter":{"hash":"dd07ca0728434bbb8f6c676335187387b0908d0533b5b641a12ddd36fe4fb1d5"},"kernelspec":{"display_name":"Python 3.8.8 64-bit ('base': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}
